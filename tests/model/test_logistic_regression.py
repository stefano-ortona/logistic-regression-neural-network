from unittest import TestCase
from model.logistic_regression import model
from model.logistic_regression import sigmoid
from model.logistic_regression import predict
import numpy as np


class TestLogisticRegression(TestCase):

    def test_sigmoid(self):
        self.assertEqual(0.7310585786300049, sigmoid(1))
        self.assertEqual(0.5, sigmoid(0))
        self.assertEqual(0.598687660112452, sigmoid(0.4))
        self.assertTrue(np.all(sigmoid(np.ones((30, 1))) == 0.7310585786300049))

    def test_model_zero_iteration(self):
        m = model(np.random.rand(50, 30), np.zeros((1, 30)), np.random.rand(50, 10), np.zeros((1, 10)), 0, 0.5, 0.5)
        self.assertTrue(np.all(m["w"] == 0))
        self.assertEqual(0, m["b"])

    def test_model_one_iteration(self):
        m = model(np.ones((50, 30)), np.zeros((1, 30)), np.random.rand(50, 10), np.zeros((1, 10)), 1, 0.5, 0.5, True)
        self.assertTrue(np.all(m["w"] == -0.25))
        self.assertEqual(-0.25, m["b"])
        self.assertEqual([0.693147180559945], m["costs"])

    def test_model_generic(self):
        x_train = np.array([[0.77679542, 0.42550277, 0.43119709, 0.84020278, 0.56289314, 0.80181711, 0.33797479,
                             0.83068135, 0.29069878, 0.64665414, 0.8399657, 0.41210452, 0.76572524, 0.3983717,
                             0.17585812, 0.78800588, 0.57632513, 0.87819233, 0.77348178, 0.86920815],
                            [0.85639999, 0.07773697, 0.88486072, 0.12133006, 0.8831966, 0.01258372, 0.43179678,
                             0.96800565, 0.85772943, 0.13272434, 0.19360984, 0.57723324, 0.96759831, 0.44677857,
                             0.82519981, 0.53714392, 0.63971177, 0.81282046, 0.79496517, 0.84249233],
                            [0.4377017, 0.07325897, 0.65143105, 0.74348883, 0.04055753, 0.86915824, 0.49866018,
                             0.53914376, 0.22747478, 0.41592383, 0.54908615, 0.28836116, 0.98930031, 0.09086554,
                             0.08045452, 0.01807639, 0.85708779, 0.89572302, 0.33044436, 0.21351548],
                            [0.40915473, 0.23010593, 0.27829993, 0.81220012, 0.71685932, 0.56986406, 0.20338336,
                             0.00761195, 0.7071755, 0.12111796, 0.45548379, 0.07667573, 0.92574579, 0.71145567,
                             0.09506447, 0.87776601, 0.56125451, 0.87054529, 0.93677464, 0.04490465],
                            [0.82593053, 0.7389101, 0.70114677, 0.52157786, 0.41381309, 0.17003997, 0.5644258,
                             0.54545592, 0.2391174, 0.02899769, 0.6805786, 0.05367975, 0.05563, 0.61875738, 0.41411869,
                             0.62690249, 0.32927423, 0.16448231, 0.29147964, 0.32915092],
                            [0.50579791, 0.26508496, 0.4760761, 0.19708722, 0.23988485, 0.8271818, 0.72101055,
                             0.31607597, 0.02307662, 0.19263967, 0.0910124, 0.28069347, 0.45888618, 0.01577641,
                             0.25288894, 0.77082562, 0.97948273, 0.7378422, 0.7354565, 0.7601866],
                            [0.39289829, 0.75805047, 0.20764996, 0.9999238, 0.32608672, 0.48226946, 0.14231531,
                             0.36591521, 0.66539357, 0.46771283, 0.57001687, 0.95788888, 0.87701256, 0.88778139,
                             0.80364622, 0.84369837, 0.98812401, 0.04390798, 0.31933199, 0.86447057],
                            [0.85235179, 0.60290573, 0.52009784, 0.56363407, 0.49904859, 0.45577986, 0.4518056,
                             0.84983423, 0.56300049, 0.94873717, 0.12559434, 0.06516135, 0.58635129, 0.0065983,
                             0.36857131, 0.58468322, 0.55092981, 0.93698873, 0.79473525, 0.89255885],
                            [0.17530518, 0.3306843, 0.88006765, 0.61764781, 0.75945166, 0.86430608, 0.28153783,
                             0.95804037, 0.52159469, 0.45893923, 0.66387046, 0.8337556, 0.18059935, 0.12569133,
                             0.9733044, 0.43154652, 0.70715201, 0.21709075, 0.88711769, 0.99925667],
                            [0.04362261, 0.40007421, 0.54117005, 0.41404844, 0.59214215, 0.30083474, 0.69955164,
                             0.68430633, 0.22019415, 0.21259852, 0.79513502, 0.44657098, 0.60298384, 0.412864,
                             0.24103478, 0.42530395, 0.01582054, 0.47125953, 0.63426745, 0.05661412]])

        y_train = np.array([[1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0]])
        x_test = np.array([[0.40995267, 0.30639854, 0.57019573, 0.77648254, 0.97561985],
                           [0.79282747, 0.92727103, 0.82385727, 0.38337183, 0.14214305],
                           [0.69544155, 0.15961494, 0.23330569, 0.70195222, 0.50318119],
                           [0.88815772, 0.74437836, 0.86015867, 0.83638187, 0.2832056],
                           [0.03331586, 0.66361354, 0.73811017, 0.78383852, 0.12442313],
                           [0.83263567, 0.88689302, 0.39361916, 0.01633149, 0.12030189],
                           [0.29767108, 0.13752181, 0.15006358, 0.90016588, 0.65686797],
                           [0.71050689, 0.04602483, 0.14459697, 0.77678, 0.72762633],
                           [0.38891781, 0.19091966, 0.79648012, 0.14057416, 0.83705591],
                           [0.00484497, 0.90208492, 0.51978655, 0.80715782, 0.16807246]])
        y_test = np.array([[1, 1, 1, 0, 0]])

        m = model(x_train, y_train, x_test, y_test, 2000, 0.005, 0.5, True)
        self.assertEqual(0.24157106385509128, m["w"][0][0])
        self.assertEqual(-0.19311327643855156, m["w"][3][0])
        self.assertEqual(0.22514003840042154, m["w"][9][0])
        self.assertEqual(0.17884209821576572, m["b"])
        self.assertEqual(1., m["prediction_train"][0][0])
        self.assertEqual(0., m["prediction_train"][0][8])
        self.assertEqual(0., m["prediction_train"][0][12])
        self.assertEqual(1., m["prediction_train"][0][19])
        self.assertTrue(np.all(m["prediction_test"] == 1., axis=1))
        self.assertEqual([0.6931471805599453, 0.6795658476660819, 0.672441818067934, 0.6678495461311831,
                          0.6642778632612754, 0.6611400870248212, 0.6582059942698141, 0.6553842021477584,
                          0.6526378736226983, 0.6499517385003519, 0.6473190944148755, 0.6447366570379752,
                          0.6422025132992564, 0.639715306399862, 0.637273911064024, 0.6348773041721282,
                          0.6325245132962592, 0.630214596280424, 0.627946633169597, 0.6257197230311383],
                         m["costs"])

    def test_predict_all_zeros(self):
        w = np.array([[0.], [0.]])
        b = -0.2
        x = np.array([[3.4, -1.7, -4.2], [8.2, 14., 10.1]])
        prediction = predict(x, w, b, 0.5)
        self.assertEqual(0., prediction[0][0])
        self.assertEqual(0., prediction[0][1])
        self.assertEqual(0., prediction[0][2])

    def test_predict_all_ones(self):
        w = np.array([[1.], [1.]])
        b = 5.
        x = np.array([[1., 1., 1.], [1.8, 2.3, 0.9]])
        prediction = predict(x, w, b, 0.5)
        self.assertEqual(1., prediction[0][0])
        self.assertEqual(1., prediction[0][1])
        self.assertEqual(1., prediction[0][2])

    def test_predict_generic(self):
        w = np.array([[0.75], [-0.2]])
        b = 0.1
        x = np.array([[.74, 0.24, 0.12], [0.89, 0.37, 0.9]])
        prediction = predict(x, w, b, 0.6)
        self.assertEqual(1., prediction[0][0])
        self.assertEqual(0., prediction[0][1])
        self.assertEqual(0., prediction[0][2])
